import getpass
import os
import inspect
from typing import Optional, List
from pydantic import BaseModel, Field
import json
from typing import Annotated
from typing import Literal

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from langchain.agents import Tool, initialize_agent
from langchain.schema import AgentAction, AgentFinish
from langchain.agents.agent_types import AgentType
from langchain.chains import LLMChain
from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper
from langchain_core.prompts import PromptTemplate
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition

from IPython.display import Image, display

from typing import TypedDict

from openai import OpenAI
import base64

import categorie
import ClassPers
import ClassMonde
import ClassTram
from langchain.memory import ConversationBufferMemory

os.environ["LANGSMITH_TRACING"] = "true"
if "LANGSMITH_API_KEY" not in os.environ:
    os.environ["LANGSMITH_API_KEY"] = "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"
if "LANDSMITH_PROJECT" not in os.environ:
    os.environ["LANGSMITH_PROJECT"]="default"
if "OPENAI_API_KEY" not in os.environ:
    os.environ["OPENAI_API_KEY"]="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"


model = ChatOpenAI(model="gpt-4o", temperature=0.7)
struct_roman=categorie.tirer_scenario()

# struct_roman

struct_roman_path = "Sauvegarde/struct_roman.json"
if os.path.exists(struct_roman_path):
    with open(struct_roman_path, "r", encoding="utf-8") as f:
        struct_roman = json.load(f)
    print("üìñ struct_roman charg√© depuis la sauvegarde !")
else:
    struct_roman = categorie.tirer_scenario()
    with open(struct_roman_path, "w", encoding="utf-8") as f:
        json.dump(struct_roman, f, ensure_ascii=False, indent=2)
    print("üìñ struct_roman g√©n√©r√© et sauvegard√© !")

# G√©n√©ration du shema narratif principal

SCHEMA_PRINCIPAL_CLASSES = {
    name: cls
    for name, cls in inspect.getmembers(ClassTram, inspect.isclass)
    if cls.__module__ == ClassTram.__name__
}

shema_principal_path = "Sauvegarde/shema_narratif_principal.json"
if os.path.exists(shema_principal_path):
    with open(shema_principal_path, "r", encoding="utf-8") as f:
        Shema_narratif_principal = json.load(f)
    print("üìù Sch√©ma narratif principal charg√© depuis la sauvegarde !")
else:
    schema_principal_class = SCHEMA_PRINCIPAL_CLASSES[struct_roman["schema_principal"]]
    Shema_principale_struct = model.with_structured_output(schema_principal_class)
    message = [
        SystemMessage(content="Tu es un assistant narratif sp√©cialis√© en fiction."),
        SystemMessage(content=f"Ta mission est de g√©n√©rer les shema narratif principale de l'histoire sous la forme d'un {struct_roman['schema_principal']}."),
        SystemMessage(content=f"La structure du roman est la suivante: {struct_roman}"),
        HumanMessage(content=f"Ecrit le shema narratif principal, n'h√©site pas √©crire 3 √† 5 lignes pour chaque champs de la classe")
    ]
    Shema_narratif_principal = Shema_principale_struct.invoke(message).model_dump()
    with open(shema_principal_path, "w", encoding="utf-8") as f:
        json.dump(Shema_narratif_principal, f, ensure_ascii=False, indent=2)
    print("üìù Sch√©ma narratif principal g√©n√©r√© et sauvegard√© !")

# G√©n√©ration du monde ou se passe l'histoire

monde_path = "Sauvegarde/monde_sauvegarde.json"
if os.path.exists(monde_path):
    with open(monde_path, "r", encoding="utf-8") as f:
        Monde = json.load(f)
    print("üåç Monde charg√© depuis la sauvegarde !")
else:
    monde_struct = model.with_structured_output(ClassMonde.Monde)

    message = [
        SystemMessage(content="Tu es un assistant narratif sp√©cialis√© en fiction."),
        SystemMessage(content=f"Ta mission est de g√©n√©rer un monde fictif o√π l'histoire prend places"),
        SystemMessage(content=f"Tu dois prendre en compte la structure suivante : {struct_roman}"),
        SystemMessage(content=f"Tu dois prendre le shema narratif suivant : {Shema_narratif_principal}"),
        HumanMessage(content="G√©n√®re un monde fictif coh√©rent avec la structure du roman et le sch√©ma narratif principal")
    ]

    Monde = monde_struct.invoke(message).model_dump()
    with open(monde_path, "w", encoding="utf-8") as f:
        json.dump(Monde, f, ensure_ascii=False, indent=2)
    print("üåç Monde g√©n√©r√© et sauvegard√© !")

# G√©n√©ration des personnages

personnages_path = "Sauvegarde/personnages.json"
if os.path.exists(personnages_path):
    with open(personnages_path, "r", encoding="utf-8") as f:
        PersonnageDict = json.load(f)
    print("üë§ Personnages charg√©s depuis la sauvegarde !")
else:
    Pers_struct = model.with_structured_output(ClassPers.ListePersonnages)
    message = [
        SystemMessage(content="Tu es un assistant narratif sp√©cialis√© en fiction."),
        SystemMessage(content="Ta mission est de g√©n√©rer des personnages coh√©rents avec l'univers donn√©."),
        SystemMessage(content=f"Structure du roman : {struct_roman}"),
        SystemMessage(content=f"Monde ou prend place l'histoire : {Monde}"),
        SystemMessage(content=f"Sch√©ma narratif principal de l'histoire : {Shema_narratif_principal}"),
        HumanMessage(content="G√©n√®re un personnage principal, selon les besoins entre 3 √† 5 personnages secondaires majeurs et entre 1 et 5 personnages secondaires mineurs")
    ]
    PersonnageDict = Pers_struct.invoke(message).model_dump()
    with open(personnages_path, "w", encoding="utf-8") as f:
        json.dump(PersonnageDict, f, ensure_ascii=False, indent=2)
    print("üë§ Personnages g√©n√©r√©s et sauvegard√©s !")

# G√©n√©ration du shema narratif compl√©mentaire

shema_complementaire_path = "Sauvegarde/shema_complementaire_narratif.json"
if os.path.exists(shema_complementaire_path):
    with open(shema_complementaire_path, "r", encoding="utf-8") as f:
        Shema_complementaire_narratif = json.load(f)
    print("üìù Sch√©ma narratif compl√©mentaire charg√© depuis la sauvegarde !")
else:
    SHEMA_COMPLEMENTAIRE_CLASSES = {
        name: clas
        for name, clas in inspect.getmembers(ClassTram, inspect.isclass)
        if clas.__module__ == ClassTram.__name__
    }
    Shema_complementaire_struct = model.with_structured_output(SHEMA_COMPLEMENTAIRE_CLASSES[struct_roman["schema_complementaire"]])
    message = [
        SystemMessage(content="Tu es un assistant narratif sp√©cialis√© en fiction."),
        SystemMessage(content=f"Ta mission est de g√©n√©rer les shema narratif secondaire de l'histoire sous la forme d'un {struct_roman['schema_complementaire']}."),
        SystemMessage(content=f"La structure du roman est la suivante : {struct_roman}"),
        SystemMessage(content=f"Monde ou prend place l'histoire : {Monde}"),
        SystemMessage(content=f"Shema narratif principal de l'histoire : {Shema_narratif_principal}"),
        HumanMessage(content=f"Ecrit un shema narratif secondaire, n'h√©site pas √©crire 3 √† 5 lignes pour chaque champs de la classe")
    ]
    Shema_complementaire_narratif = Shema_complementaire_struct.invoke(message).model_dump()
    with open(shema_complementaire_path, "w", encoding="utf-8") as f:
        json.dump(Shema_complementaire_narratif, f, ensure_ascii=False, indent=2)
    print("üìù Sch√©ma narratif compl√©mentaire g√©n√©r√© et sauvegard√© !")

# G√©n√©ration des chapitres avec une description pour chaque chapitre

class ChapitreClass(BaseModel):
    titre: str = Field(description="Le titre du chapitre")
    description: str = Field(description="Une courte description de, 3 √† 4 lignes de ce qui va se passer dans le chapitre")

class ListeChapitres(BaseModel):
    """Une liste de chapitres pour le roman"""
    chapitres: List[ChapitreClass] = Field(description="Liste des chapitres du roman avec titre et description")

chapitres_path = "Sauvegarde/chapitres.json"
if os.path.exists(chapitres_path):
    with open(chapitres_path, "r", encoding="utf-8") as f:
        ChapitresPourMarkdown = json.load(f)
    print("üìö Chapitres charg√©s depuis la sauvegarde !")
else:
    Chapitres_struct = model.with_structured_output(ListeChapitres)
    message = [
        SystemMessage(content="Tu es un assistant narratif sp√©cialis√© en fiction."),
        SystemMessage(content="Ta mission est de g√©n√©rer la liste des chapitres du roman. Pour chaque chapitre, donne un titre et une description de quelques lignes expliquant ce qui va se passer dans le chapitre."),
        SystemMessage(content=f"Nombre de chapitres: {struct_roman['nombre_chapitres']}"),
        SystemMessage(content=f"Structure du roman : {struct_roman}"),
        SystemMessage(content=f"Monde o√π prend place l'histoire : {Monde}"),
        SystemMessage(content=f"Sch√©ma narratif principal de l'histoire : {Shema_narratif_principal}"),
        SystemMessage(content=f"Sch√©ma narratif compl√©mentaire de l'histoire : {Shema_complementaire_narratif}"),
        SystemMessage(content=f"Liste des personnages : {PersonnageDict}"),
        HumanMessage(content="G√©n√®re la liste compl√®te des chapitres du roman avec une description de quelques lignes pour chaque chapitre.")
    ]
    Chapitres = Chapitres_struct.invoke(message).model_dump()
    ChapitresPourMarkdown = { i + 1: chapitre for i, chapitre in enumerate(Chapitres['chapitres']) }
    with open(chapitres_path, "w", encoding="utf-8") as f:
        json.dump(ChapitresPourMarkdown, f, ensure_ascii=False, indent=2)
    print("üìö Chapitres g√©n√©r√©s et sauvegard√©s !")

# G√©n√©ration du titre du roman

titre_path = "Sauvegarde/titre.txt"
if os.path.exists(titre_path):
    with open(titre_path, "r", encoding="utf-8") as f:
        Titre = f.read().strip()
    print("üè∑Ô∏è Titre charg√© depuis la sauvegarde !")
else:
    message = [
        SystemMessage(content="Tu es un assistant narratif sp√©cialis√© en fiction."),
        SystemMessage(content="Ta mission est de g√©n√©rer le titre du roman."),
        SystemMessage(content=f"Structure du roman : {struct_roman}"),
        SystemMessage(content=f"Monde o√π prend place l'histoire : {Monde}"),
        SystemMessage(content=f"Sch√©ma narratif principal de l'histoire : {Shema_narratif_principal}"),
        SystemMessage(content=f"Sch√©ma narratif compl√©mentaire de l'histoire : {Shema_complementaire_narratif}"),
        SystemMessage(content=f"Liste des personnages : {PersonnageDict}"),
        SystemMessage(content=f"Liste des chapitres : {ChapitresPourMarkdown}"),
        SystemMessage(content=f"Retourne que le titre du roman, sans explication ni description, juste le titre."),
        HumanMessage(content="Propose un titre original et accrocheur pour ce roman.")
    ]
    Titre = model.invoke(message).content
    with open(titre_path, "w", encoding="utf-8") as f:
        f.write(Titre)
    print("üè∑Ô∏è Titre g√©n√©r√© et sauvegard√© !")

# G√©n√©ration du roman en entier

full_chapitre_path = "Sauvegarde/full_chapitre.json"

if os.path.exists(full_chapitre_path):
    with open(full_chapitre_path, "r", encoding="utf-8") as f:
        full_chapitre = f.read().strip()
    print("üìñ Roman complet charg√© depuis la sauvegarde !")
else:
    messageInitialisation = [
        SystemMessage(content="Tu es un assistant narratif sp√©cialis√© en fiction."),
        SystemMessage(content=f"Ta mission est d'√©crire un chapitre entier du roman, en respectant la taille indiqu√©e qui est de environ {struct_roman['caracteres_par_chapitre']} caract√®res."),
        SystemMessage(content="Tu peux t'aider des outils √† ta disposition pour acc√©der √† tout √©l√©ment utile (structure du roman, monde, personnages, sch√©mas narratifs, description du chapitre, shema_complementaire_narratif, etc). N'h√©site pas √† les utiliser pour garantir la coh√©rence et la richesse du r√©cit."),
        SystemMessage(content="Tu en est actuellement au chapitre 1, tu dois donc √©crire le premier chapitre du roman."),
        SystemMessage(content=f"Voici la structure du roman : {struct_roman}"),
        SystemMessage(content=f"Monde o√π prend place l'histoire : {Monde}"),
        SystemMessage(content=f"Sch√©ma narratif principal (√† garder en m√©moire) : {Shema_narratif_principal}"),
        SystemMessage(content=f"Sch√©ma narratif compl√©mentaire (√† garder en m√©moire) : {Shema_complementaire_narratif}"),
        SystemMessage(content=f"Liste des personnages (√† garder en m√©moire): {PersonnageDict}"),
        SystemMessage(content=f"R√©sum√© rapide de l'id√©e principale du chapitre √† √©crire : {ChapitresPourMarkdown['1']['description']}"),
        SystemMessage(content=f"Titre du chapitre a √©crire : {ChapitresPourMarkdown['1']['titre']}"),
        SystemMessage(content="N'oublie pas de respecter la coh√©rence avec les chapitres pr√©c√©dents et d'assurer la continuit√© de l'intrigue."),
        HumanMessage(content="√âcris le chapitre complet.")
    ]

    messageBoucle = [
        SystemMessage(content="Tu es un assistant narratif sp√©cialis√© en fiction."),
        SystemMessage(content=f"Ta mission est d'√©crire un chapitre entier du roman, en respectant la taille indiqu√©e qui est de environ {struct_roman['caracteres_par_chapitre']} caract√®res."),
        SystemMessage(content="Tu peux t'aider des outils √† ta disposition pour acc√©der √† tout √©l√©ment utile (structure du roman, monde, personnages, sch√©mas narratifs, description du chapitre, shema_complementaire_narratif, etc). N'h√©site pas √† les utiliser pour garantir la coh√©rence et la richesse du r√©cit."),
        SystemMessage(content=f"Tu √©crit actuellement le chapitre num√©ro :"),
        SystemMessage(content=f"R√©sum√© rapide de l'id√©e principale du chapitre √† √©crire :"),
        SystemMessage(content=f"Titre du chapitre a √©crire :") ,
        SystemMessage(content=f"R√©sumer de l'emsemble des chapitres pr√©c√©dent √©crit : "),
        SystemMessage(content="Tu n'as le droit d'appeler les outils qu'une seule fois, si tu les as d√©j√† appel√©s et que tu as une r√©ponse, √©cris le chapitre avec les infos que tu as."),
        SystemMessage(content=""),
        SystemMessage(content="N'oublie pas de respecter la coh√©rence avec les chapitres pr√©c√©dents et d'assurer la continuit√© de l'intrigue."),
        HumanMessage(content="√âcris le chapitre complet.")
    ]

    class ChapterState(TypedDict, total=False):
        """√âtat du chapitre en cours d'√©criture."""
        Index: int  # Index du chapitre (par d√©faut 1)
        Texte: List[str]
        Recap: List[str]
        messages: Annotated[list, add_messages]


    # Cr√©ation des outils pour l'agent

    def get_struct_roman(input_str=None) -> str:
        """Retourne la structure du roman sous forme de texte JSON format√©."""
        return json.dumps(struct_roman, ensure_ascii=False, indent=2)

    def get_monde(input_str=None) -> str:
        """Retourne la description du monde sous forme de texte JSON format√©."""
        return json.dumps(Monde, ensure_ascii=False, indent=2)

    def get_shema_narratif_principal(input_str=None) -> str:
        """Retourne le sch√©ma narratif principal sous forme de texte JSON format√©."""
        return json.dumps(Shema_narratif_principal, ensure_ascii=False, indent=2)

    def get_shema_complementaire_narratif(input_str=None) -> str:
        """Retourne le sch√©ma narratif compl√©mentaire sous forme de texte JSON format√©."""
        return json.dumps(Shema_complementaire_narratif, ensure_ascii=False, indent=2)

    def get_personnages(input_str=None) -> str:
        """Retourne la liste des personnages sous forme de texte JSON format√©."""
        return json.dumps(PersonnageDict, ensure_ascii=False, indent=2)

    def get_description_chapitre(nbchap: int = 0) -> str:
        """Retourne la description du chapitre courant."""
        return ChapitresPourMarkdown[str(nbchap + 1)]['description']

    Tools = [
        Tool(
            name="AfficherStructureRoman",
            func=lambda _: get_struct_roman(),
            description="Affiche la structure du roman (struct_roman) au format JSON."
        ),
        Tool(
            name="AfficherMonde",
            func=lambda _: get_monde(),
            description="Affiche la description du monde fictif (Monde) au format JSON."
        ),
        Tool(
            name="AfficherSchemaNarratifPrincipal",
            func=lambda _: get_shema_narratif_principal(),
            description="Affiche le sch√©ma narratif principal (Shema_narratif_principal) au format JSON."
        ),
        Tool(
            name="AfficherSchemaNarratifComplementaire",
            func=lambda _: get_shema_complementaire_narratif(),
            description="Affiche le sch√©ma narratif compl√©mentaire (Shema_complementaire_narratif) au format JSON."
        ),
        Tool(
            name="AfficherPersonnages",
            func=lambda _: get_personnages(),
            description="Affiche la liste des personnages (PersonnageDict) au format JSON."
        ),
        Tool(
            name="AfficherDescriptionChapitre",
            func=lambda x: get_description_chapitre(int(x)),
            description="Affiche la description du chapitre dont le num√©ro est pass√© en argument (commence √† 0)."
        )
    ]

    llm_with_tools = model.bind_tools(Tools)

    print(f"nb chap : {struct_roman['nombre_chapitres']}")

    def WriteTexteChapitre(chapitre: ChapterState) -> dict:
        """√âcrit le texte du chapitre en cours."""
        print(f"[WriteTexteChapitre] D√©but - Index chapitre : {chapitre['Index']}")
        if chapitre["Index"] == 0:
            print("[WriteTexteChapitre] Utilisation du message d'initialisation")
            msg = llm_with_tools.invoke(messageInitialisation)
        else:
            print(f"[WriteTexteChapitre] Utilisation du message de boucle pour le chapitre {chapitre['Index']+1}")
            messageBoucle[3] = SystemMessage(content=f"Tu √©crit le chapitre numero : {chapitre['Index']+1}")
            messageBoucle[4] = SystemMessage(content=f"R√©sum√© rapide de l'id√©e principale du chapitre √† √©crire : {ChapitresPourMarkdown[str(chapitre['Index']+1)]['description']}")
            messageBoucle[5] = SystemMessage(content=f"Titre du chapitre a √©crire : {ChapitresPourMarkdown[str(chapitre['Index']+1)]['titre']}")
            messageBoucle[6] = SystemMessage(content=f"R√©sumer de l'emsemble des chapitres pr√©c√©dent √©crit : {chapitre['Recap']}")
            
            # ‚úÖ MODIFIER : Prendre seulement les 2 derniers messages et les mettre en position 8
            if chapitre.get("messages") and len(chapitre["messages"]) > 0:
                derniers_messages = chapitre["messages"][-2:]  # ‚úÖ Seulement les 2 derniers
                # Cr√©er une cha√Æne de contexte avec les 2 derniers messages
                contexte_messages = ""
                for i, msg in enumerate(derniers_messages):
                    if hasattr(msg, 'content'):
                        contexte_messages += f"Message {i+1}: {msg.content}\n"
                
                messageBoucle[8] = SystemMessage(content=f"Contexte des 2 derniers √©changes:\n{contexte_messages}")
            else:
                messageBoucle[8] = SystemMessage(content="Pas de contexte pr√©c√©dent disponible.")

            messageBoucle[7] = SystemMessage(content="ATTENTION, tu n'a le droit d'appeler les outils qu'une seule fois. Si tu as besoin d'informations compl√©mentaires pour enrichir le chapitre, utilise les outils disponibles. Une fois que tu as toutes les informations n√©cessaires, √©cris le chapitre complet.")

            msg = llm_with_tools.invoke(messageBoucle)
        
        has_tool_calls = hasattr(msg, 'tool_calls') and len(msg.tool_calls)

        if not has_tool_calls:
            print("[WriteTexteChapitre] Pas d'appel d'outil, ajout du texte du chapitre")
            chapter_text = msg.content
            chapitre["Texte"].append(chapter_text)
            print(f"[WriteTexteChapitre] Texte du chapitre ajout√©. Total chapitres √©crits : {len(chapitre['Texte'])}")
            return {"Texte": chapitre["Texte"], "messages": [msg]}
        else:
            print("[WriteTexteChapitre] Appel d'outil d√©tect√©, passage √† l'√©tape suivante")
            return {"Texte": chapitre["Texte"], "messages": [msg]}

    def WriteRecapChapitre(chapitre: ChapterState) -> dict:
        """√âcrit le recapitulatif du chapitre en cours avec m√©moire d√©di√©e."""
        print(f"[WriteRecapChapitre] D√©but - Index chapitre : {chapitre['Index']}")
        messageRecap = [
            SystemMessage(content="Tu es un assistant narratif sp√©cialis√© en fiction."),
            SystemMessage(content="Ta mission est de g√©n√©rer un r√©capitulatif du chapitre √©crit de 5 lignes grand maximum."),
            HumanMessage(content=f"Voici le chapitre a r√©sumer : {chapitre['Texte'][chapitre['Index']]}"),
        ]
        msg = model.invoke(messageRecap)
        chapitre["Recap"].append(msg.content)
        print(f"[WriteRecapChapitre] R√©capitulatif ajout√©. Total r√©capitulatifs : {len(chapitre['Recap'])}")
        return {"Recap": chapitre["Recap"]}

    def UpIndex(chapitre: ChapterState) -> dict:
        """Met √† jour l'index du chapitre en cours."""
        chapitre["Index"] += 1
        print(f"[UpIndex] Passage au chapitre suivant. Nouvel index : {chapitre['Index']}")
        return {"Index": chapitre["Index"]}

    tool_node = ToolNode(tools=Tools)

    graph_builder = StateGraph(ChapterState)

    graph_builder.add_node("WriteTexteChapitre", WriteTexteChapitre)
    graph_builder.add_node("WriteRecapChapitre", WriteRecapChapitre)
    graph_builder.add_node("UpIndex", UpIndex)
    graph_builder.add_node("tools", tool_node)

    def boucle_decision(chapitre: ChapterState) -> str:
        """Condition pour continuer ou arr√™ter l'√©criture des chapitres."""
        print(f"J'appelle boucle d√©cision")
        if chapitre["Index"] >= struct_roman['nombre_chapitres']:
            return "END"
        else:
            return "WriteTexteChapitre"
        
    def route_tool(chapitre: ChapterState) -> Literal["WriteRecapChapitre", "tools"]:
        if len(chapitre["messages"][-1].tool_calls) == 0:
            return "WriteRecapChapitre"
        else:
            return "tools"

    graph_builder.add_edge(START, "WriteTexteChapitre")
    graph_builder.add_conditional_edges(
        "WriteTexteChapitre",
        route_tool,
        {"WriteRecapChapitre": "WriteRecapChapitre", "tools": "tools"}
    )
    graph_builder.add_edge("tools", "WriteTexteChapitre")
    #graph_builder.add_edge("WriteTexteChapitre", "WriteRecapChapitre")
    graph_builder.add_edge("WriteRecapChapitre", "UpIndex")
    graph_builder.add_conditional_edges(
        "UpIndex",
        boucle_decision,
        {"WriteTexteChapitre": "WriteTexteChapitre", "END": END}
    )

    graph_workflow = graph_builder.compile()

    png_data = graph_workflow.get_graph().draw_mermaid_png()
    with open("graph.png", "wb") as f:
        f.write(png_data)
    print("Graphe sauvegard√© dans graph.png")

    chapter_state = graph_workflow.invoke(
        {"Index": 0, "Texte": [], "Recap": [],"messages": []},
        config={"recursion_limit": 300}
        )

    with open(full_chapitre_path, "w", encoding="utf-8") as f:
        json.dump(chapter_state['Texte'], f, ensure_ascii=False, indent=2)
    print(f"üìñ Chapitres complets √©crits et sauvegard√©s dans {full_chapitre_path} !")